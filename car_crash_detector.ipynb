{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "56lwEQVts72M",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "60d7d1a0-c52f-41af-c4fa-39fef43cad8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "r5K5XLrUGMki",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "729c3f53-c80a-4816-a2b0-1506844a8122"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
      "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
      "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
      "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  match = re.search('\\d+$', rotation_line)\n",
      "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  if event.key is 'enter':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from moviepy.editor import VideoFileClip\n",
    "from keras import layers, applications\n",
    "from datasets import load_dataset\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.nn.functional as FF\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2, os, gc, torch, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e133b5e8c7134c88b36e5d401ed93901",
      "4b42f46ccbcb4531925b22d0add8adff",
      "b570bf85d6134b89a96e4d0c651883e7",
      "72b8aa5eab7e4a70b1003d28e22529f2",
      "ace7c1ffee2e40059a7104e5982c8234",
      "cbe786df26274eee8d55b0458d249683",
      "274eeaf300f04b109dd5fa84423c0051",
      "d344b463d7e34478bd51bcf79fed93b6",
      "a872b854b5784842b49bce3fcbb36f7d",
      "09b68e8440364a438fa1489fc1730799",
      "d9c161330d8e4dc4b7fd32b4875a8886",
      "a850911a75b2470d8695975023adc0ba",
      "a633de00a0784373a9b5e12ae464d356",
      "8313904d2c004a37b0cb3c3bf5e82409",
      "9cafb763530b478496a7ace1c5ab8351",
      "72e95d3c867249708c21428ac137f459",
      "d76363ac79b1400b8f7d99fd3eb01c04",
      "6b9e601d42014f358a7cb7f4a176ef13",
      "22117069aa9f4fb1977ade4b5bc44c58",
      "b4465c1d53d84e77bf2095ac06b94118",
      "ba7fd9f5b1aa4072be6226a08a84355d",
      "e45895be91224e159c4202e01381dcda"
     ]
    },
    "id": "299ub9AbtTYA",
    "outputId": "f23fd0a6-f07c-4f04-d257-f28afea167f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e133b5e8c7134c88b36e5d401ed93901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a850911a75b2470d8695975023adc0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while True :\n",
    "    try :\n",
    "        ds = load_dataset('nexar-ai/nexar_collision_prediction', split='train')\n",
    "        break\n",
    "\n",
    "    except :\n",
    "        time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1TwOr4Ad_tsC"
   },
   "outputs": [],
   "source": [
    "n = round(ds.num_rows * 0.6)\n",
    "subset = ds.shuffle(seed=1404).select(range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UdBa8Xtvtcs7"
   },
   "outputs": [],
   "source": [
    "train_df = subset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7f11eX2VbE_T"
   },
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['time_of_event'].apply(lambda x: 0 if pd.isna(x) or x is None else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mbF_a676cyPI"
   },
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(\n",
    "    train_df,\n",
    "    columns=['light_conditions', 'weather', 'scene'],\n",
    "    prefix=['light', 'weather', 'scene'],\n",
    "    dtype=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7781WD8Whpv9"
   },
   "outputs": [],
   "source": [
    "train_df_split, val_df_split = train_test_split(train_df, test_size=0.3, random_state=1404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81feoejPGdHd",
    "outputId": "1add9b5c-0d05-4bd7-f6cf-74b2a681c5b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [15:19<00:00,  1.46s/it]\n",
      "100%|██████████| 270/270 [06:30<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'video_matrices'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def resize_on_gpu(frames):\n",
    "    # Convert (N, H, W, C) -> (N, C, H, W)\n",
    "    frames_tensor = torch.from_numpy(frames).permute(0, 3, 1, 2).float().to(device)\n",
    "    # Resize to (224, 224)\n",
    "    resized = F.resize(frames_tensor, [224, 224])\n",
    "    # Back to (N, H, W, C)\n",
    "    return resized.permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "def video_to_matrix(video_df, is_train=True, frame_interval=6):\n",
    "    for idx, row in tqdm(video_df.iterrows(), total=len(video_df)):\n",
    "        video_path = row['video']['path']\n",
    "        time_of_event = row['time_of_event']\n",
    "        label = row['label']\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f'[WARN] Cannot open video at index {idx}: {video_path}')\n",
    "            continue\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        if fps == 0 or fps is None:\n",
    "            print(f'[WARN] FPS is zero at index {idx}')\n",
    "            cap.release()\n",
    "            continue\n",
    "\n",
    "        total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        duration = total_frames / fps\n",
    "\n",
    "        if label :\n",
    "            start_time = time_of_event - 2\n",
    "            end_time = time_of_event\n",
    "        else :\n",
    "            random_time = np.random.uniform(0, duration - 2)\n",
    "            start_time = random_time\n",
    "            end_time = random_time + 2\n",
    "\n",
    "        start_frame = int(start_time * fps)\n",
    "        end_frame = int(end_time * fps)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "        frames = []\n",
    "        frame_index = start_frame\n",
    "\n",
    "        while frame_index <= end_frame:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            if frame_index % frame_interval == 0:\n",
    "                frames.append(frame)\n",
    "            frame_index += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if frames:\n",
    "            frames = np.stack(frames)  # (N, H, W, 3)\n",
    "            video_matrix = resize_on_gpu(frames)  # GPU accelerated resize\n",
    "            save_path = os.path.join(output_dir, f'video_{idx}.npy')\n",
    "            np.save(save_path, video_matrix)\n",
    "\n",
    "        del frames\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "# Run it\n",
    "video_to_matrix(train_df_split)\n",
    "video_to_matrix(val_df_split, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "I_tHhlu4acKv"
   },
   "outputs": [],
   "source": [
    "def add_matrix_path_col(df) :\n",
    "  output_dir = 'video_matrices'\n",
    "  df['video_matrix_path'] = None\n",
    "\n",
    "  for idx in df.index:\n",
    "      file_path = os.path.join(output_dir, f'video_{idx}.npy')\n",
    "      if os.path.exists(file_path):\n",
    "          df.at[idx, 'video_matrix_path'] = file_path\n",
    "      else:\n",
    "          df.at[idx, 'video_matrix_path'] = None\n",
    "\n",
    "add_matrix_path_col(train_df_split)\n",
    "add_matrix_path_col(val_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHBcFHrN_LWS",
    "outputId": "b134ac23-65e7-4508-bdd3-a76eea2de080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [06:53<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [02:56<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "def masked_video_to_matrix(df):\n",
    "    output_dir = 'masked_video_matrices'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    for idx, video in tqdm(df.iterrows(), total=len(df)):\n",
    "        video_path = '/content/' + video['video_matrix_path']\n",
    "        video_frames = np.load(video_path)  # (N, H, W, 3)\n",
    "        frames_tensor = torch.from_numpy(video_frames).permute(0, 3, 1, 2).float().to(device) / 255.0\n",
    "        num_frames = frames_tensor.shape[0]\n",
    "\n",
    "        mask_frames = []\n",
    "\n",
    "        # Convert to grayscale on GPU\n",
    "        gray = 0.2989 * frames_tensor[:, 0] + 0.5870 * frames_tensor[:, 1] + 0.1140 * frames_tensor[:, 2]\n",
    "\n",
    "        for i in range(1, num_frames):\n",
    "            prev_gray = gray[i - 1:i]  # (1, H, W)\n",
    "            next_gray = gray[i:i + 1]\n",
    "\n",
    "            # Optical flow approximation using spatial gradients\n",
    "            # Compute gradients with Sobel kernels\n",
    "            sobel_x = torch.tensor([[1, 0, -1],\n",
    "                                    [2, 0, -2],\n",
    "                                    [1, 0, -1]], dtype=torch.float32, device=device).view(1, 1, 3, 3)\n",
    "            sobel_y = torch.tensor([[1, 2, 1],\n",
    "                                    [0, 0, 0],\n",
    "                                    [-1, -2, -1]], dtype=torch.float32, device=device).view(1, 1, 3, 3)\n",
    "\n",
    "            Ix = FF.conv2d(prev_gray.unsqueeze(0), sobel_x, padding=1)\n",
    "            Iy = FF.conv2d(prev_gray.unsqueeze(0), sobel_y, padding=1)\n",
    "            It = next_gray.unsqueeze(0) - prev_gray.unsqueeze(0)\n",
    "\n",
    "            # Lucas–Kanade flow per-pixel in 3×3 window\n",
    "            kernel = torch.ones((1, 1, 3, 3), device=device)\n",
    "            Ixx = FF.conv2d(Ix * Ix, kernel, padding=1)\n",
    "            Iyy = FF.conv2d(Iy * Iy, kernel, padding=1)\n",
    "            Ixy = FF.conv2d(Ix * Iy, kernel, padding=1)\n",
    "            Ixt = FF.conv2d(Ix * It, kernel, padding=1)\n",
    "            Iyt = FF.conv2d(Iy * It, kernel, padding=1)\n",
    "\n",
    "            det = Ixx * Iyy - Ixy * Ixy + 1e-6\n",
    "            u = (Iyy * (-Ixt) - Ixy * (-Iyt)) / det\n",
    "            v = (-Ixy * (-Ixt) + Ixx * (-Iyt)) / det\n",
    "\n",
    "            u, v = u[0, 0], v[0, 0]  # (H, W)\n",
    "\n",
    "            # Magnitude / angle\n",
    "            magnitude = torch.sqrt(u ** 2 + v ** 2)\n",
    "            angle = torch.atan2(v, u) * (180.0 / np.pi / 2.0)\n",
    "\n",
    "            # Normalize magnitude → [0,255]\n",
    "            magnitude = 255 * (magnitude - magnitude.min()) / (magnitude.max() - magnitude.min() + 1e-6)\n",
    "\n",
    "            # Divergence\n",
    "            dy_u, dx_u = torch.gradient(u)\n",
    "            dy_v, dx_v = torch.gradient(v)\n",
    "            divergence = dx_u + dy_v\n",
    "            divergence = torch.tanh(divergence)\n",
    "            divergence = ((divergence + 1.0) / 2.0) * 255\n",
    "\n",
    "            flow_channels = torch.stack([magnitude, angle, divergence], dim=0).clamp(0, 255)\n",
    "            mask_frames.append(flow_channels.to(\"cpu\", torch.uint8))\n",
    "\n",
    "        mask_frames = torch.stack(mask_frames).numpy()\n",
    "        save_path = os.path.join(output_dir, f'masked_video_{idx}.npy')\n",
    "        np.save(save_path, mask_frames)\n",
    "\n",
    "        del frames_tensor, mask_frames\n",
    "        gc.collect()\n",
    "\n",
    "masked_video_to_matrix(train_df_split)\n",
    "masked_video_to_matrix(val_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T-pH5wCoCbne"
   },
   "outputs": [],
   "source": [
    "def add_matrix_path_col(df) :\n",
    "  output_dir = 'masked_video_matrices'\n",
    "  df['masked_video_matrix_path'] = None\n",
    "\n",
    "  for idx in df.index:\n",
    "      file_path = os.path.join(output_dir, f'masked_video_{idx}.npy')\n",
    "      if os.path.exists(file_path) :\n",
    "          df.at[idx, 'masked_video_matrix_path'] = file_path\n",
    "      else:\n",
    "          df.at[idx, 'masked_video_matrix_path'] = None\n",
    "\n",
    "add_matrix_path_col(train_df_split)\n",
    "add_matrix_path_col(val_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ajcc09yjuuyv"
   },
   "outputs": [],
   "source": [
    "train_df_split = train_df_split.reset_index()\n",
    "val_df_split = val_df_split.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fLCwPSBnwBEZ"
   },
   "outputs": [],
   "source": [
    "train_df_split = train_df_split.drop(columns=['video', 'time_of_event', 'time_of_alert', 'time_to_accident', 'index'])\n",
    "val_df_split = val_df_split.drop(columns=['video', 'time_of_event', 'time_of_alert', 'time_to_accident', 'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3Nh-5sN3SyGQ"
   },
   "outputs": [],
   "source": [
    "MAX_FRAMES = 10\n",
    "def pad_or_truncate(seq, max_len):\n",
    "    seq = np.array(seq)\n",
    "    if len(seq) > max_len:\n",
    "        return seq[:max_len]\n",
    "    if len(seq) < max_len:\n",
    "        last = seq[-1]\n",
    "        padding = np.repeat(last[None, ...], max_len - len(seq), axis=0)\n",
    "        return np.concatenate([seq, padding], axis=0)\n",
    "    return seq\n",
    "\n",
    "class VideoMatrixSequence(keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size=16, target_size=(224, 224), shuffle=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.columns = self.df.columns.drop(['video_matrix_path', 'masked_video_matrix_path', 'label'])\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "\n",
    "        tabular_data = []\n",
    "        video_data = []\n",
    "        mask_data = []\n",
    "        labels = []\n",
    "\n",
    "        for i in batch_indices :\n",
    "            row = self.df.iloc[i]\n",
    "\n",
    "            video = np.load(row['video_matrix_path'])\n",
    "            frames_resized = np.stack(video)\n",
    "            frames_resized = pad_or_truncate(frames_resized, MAX_FRAMES)\n",
    "\n",
    "            mask = np.load(row['masked_video_matrix_path'])\n",
    "            mask_frames = np.stack(mask)\n",
    "            mask_frames = pad_or_truncate(mask_frames, MAX_FRAMES)\n",
    "\n",
    "            tabular_features = [row[col] for col in self.columns]\n",
    "            tabular_data.append(tabular_features)\n",
    "\n",
    "            video_data.append(frames_resized)\n",
    "            mask_data.append(mask_frames)\n",
    "            labels.append(float(row['label']))\n",
    "\n",
    "        tabular_array = np.array(tabular_data, dtype=np.float32)\n",
    "        video_array = np.array(video_data, dtype=np.float32)\n",
    "        mask_array = np.array(mask_data, dtype=np.float32)\n",
    "        labels_array = np.array(labels, dtype=np.float32)\n",
    "        labels_array = np.expand_dims(labels_array, axis=-1)\n",
    "\n",
    "        output = (\n",
    "            {\n",
    "                'video': video_array,\n",
    "                'mask_flow': mask_array,\n",
    "                'tabular': tabular_array\n",
    "            }, labels_array\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "d2wX7HylfN62"
   },
   "outputs": [],
   "source": [
    "train_seq = VideoMatrixSequence(train_df_split, batch_size=16, target_size=(224, 224))\n",
    "val_seq = VideoMatrixSequence(val_df_split, batch_size=16, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "j6ACOPvztaTY"
   },
   "outputs": [],
   "source": [
    "def augmentation_pipeline(noise_std=0.1, brightness_factor=0.2, contrast_factor=0.2):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.RandomBrightness(factor=brightness_factor),\n",
    "        layers.RandomContrast(factor=contrast_factor),\n",
    "        layers.GaussianNoise(noise_std)\n",
    "    ], name=\"augmentation_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "uqop2UXY-BFW"
   },
   "outputs": [],
   "source": [
    "def mask_cnn_net(input_shape=(3, 224, 224), dropout_rate=0.5):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Permute((2, 3, 1))(inputs)\n",
    "    x = keras.layers.Normalization(mean=0., variance=255.)(x)\n",
    "    # x = layers.TimeDistributed(augmentation_pipeline())(x)\n",
    "\n",
    "    base = applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=x,\n",
    "        pooling=None\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    return keras.Model(inputs, x, name='mask_flow_backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBRxKmhYV2yz",
    "outputId": "706fe334-a207-42a8-fda1-6706dd38fc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5398 - auc: 0.5513 - f1: 0.5440 - loss: 0.9227 - precision: 0.5408 - recall: 0.5482\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72266, saving model to best_video_model.keras\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 3s/step - accuracy: 0.5413 - auc: 0.5538 - f1: 0.5455 - loss: 0.9192 - precision: 0.5423 - recall: 0.5499 - val_accuracy: 0.7227 - val_auc: 0.8184 - val_f1: 0.7455 - val_loss: 0.5619 - val_precision: 0.6624 - val_recall: 0.8525\n",
      "Epoch 2/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7375 - auc: 0.8176 - f1: 0.7418 - loss: 0.5469 - precision: 0.7335 - recall: 0.7508\n",
      "Epoch 2: val_accuracy improved from 0.72266 to 0.75781, saving model to best_video_model.keras\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.7380 - auc: 0.8177 - f1: 0.7423 - loss: 0.5468 - precision: 0.7339 - recall: 0.7512 - val_accuracy: 0.7578 - val_auc: 0.8409 - val_f1: 0.7615 - val_loss: 0.5135 - val_precision: 0.6972 - val_recall: 0.8390\n",
      "Epoch 3/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7817 - auc: 0.8503 - f1: 0.7740 - loss: 0.4977 - precision: 0.7750 - recall: 0.7739\n",
      "Epoch 3: val_accuracy improved from 0.75781 to 0.80078, saving model to best_video_model.keras\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.7819 - auc: 0.8505 - f1: 0.7743 - loss: 0.4974 - precision: 0.7756 - recall: 0.7740 - val_accuracy: 0.8008 - val_auc: 0.8456 - val_f1: 0.8031 - val_loss: 0.4931 - val_precision: 0.7647 - val_recall: 0.8455\n",
      "Epoch 4/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7967 - auc: 0.8774 - f1: 0.8065 - loss: 0.4390 - precision: 0.8100 - recall: 0.8052\n",
      "Epoch 4: val_accuracy did not improve from 0.80078\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.7973 - auc: 0.8779 - f1: 0.8069 - loss: 0.4381 - precision: 0.8102 - recall: 0.8058 - val_accuracy: 0.7969 - val_auc: 0.8636 - val_f1: 0.7920 - val_loss: 0.4690 - val_precision: 0.7615 - val_recall: 0.8250\n",
      "Epoch 5/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8335 - auc: 0.9253 - f1: 0.8435 - loss: 0.3495 - precision: 0.8577 - recall: 0.8308\n",
      "Epoch 5: val_accuracy improved from 0.80078 to 0.80859, saving model to best_video_model.keras\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.8334 - auc: 0.9253 - f1: 0.8433 - loss: 0.3495 - precision: 0.8569 - recall: 0.8311 - val_accuracy: 0.8086 - val_auc: 0.8678 - val_f1: 0.8108 - val_loss: 0.4679 - val_precision: 0.7609 - val_recall: 0.8678\n",
      "Epoch 6/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8325 - auc: 0.9303 - f1: 0.8315 - loss: 0.3378 - precision: 0.8220 - recall: 0.8430\n",
      "Epoch 6: val_accuracy did not improve from 0.80859\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.8326 - auc: 0.9301 - f1: 0.8316 - loss: 0.3382 - precision: 0.8226 - recall: 0.8427 - val_accuracy: 0.7969 - val_auc: 0.8867 - val_f1: 0.7920 - val_loss: 0.4376 - val_precision: 0.7444 - val_recall: 0.8462\n",
      "Epoch 7/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8863 - auc: 0.9542 - f1: 0.8905 - loss: 0.2815 - precision: 0.9027 - recall: 0.8791\n",
      "Epoch 7: val_accuracy did not improve from 0.80859\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.8862 - auc: 0.9541 - f1: 0.8903 - loss: 0.2816 - precision: 0.9024 - recall: 0.8791 - val_accuracy: 0.7773 - val_auc: 0.8620 - val_f1: 0.7711 - val_loss: 0.4826 - val_precision: 0.7385 - val_recall: 0.8067\n",
      "Epoch 8/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8928 - auc: 0.9573 - f1: 0.8911 - loss: 0.2651 - precision: 0.8797 - recall: 0.9030\n",
      "Epoch 8: val_accuracy did not improve from 0.80859\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.8923 - auc: 0.9572 - f1: 0.8907 - loss: 0.2656 - precision: 0.8794 - recall: 0.9026 - val_accuracy: 0.7930 - val_auc: 0.8829 - val_f1: 0.7954 - val_loss: 0.4488 - val_precision: 0.7410 - val_recall: 0.8583\n",
      "Epoch 9/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8846 - auc: 0.9562 - f1: 0.8869 - loss: 0.2653 - precision: 0.8744 - recall: 0.9013\n",
      "Epoch 9: val_accuracy did not improve from 0.80859\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.8847 - auc: 0.9563 - f1: 0.8871 - loss: 0.2651 - precision: 0.8747 - recall: 0.9012 - val_accuracy: 0.7852 - val_auc: 0.8663 - val_f1: 0.7843 - val_loss: 0.4930 - val_precision: 0.7463 - val_recall: 0.8264\n",
      "Epoch 10/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9364 - auc: 0.9801 - f1: 0.9376 - loss: 0.1888 - precision: 0.9469 - recall: 0.9287\n",
      "Epoch 10: val_accuracy did not improve from 0.80859\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9361 - auc: 0.9799 - f1: 0.9372 - loss: 0.1895 - precision: 0.9464 - recall: 0.9284 - val_accuracy: 0.7930 - val_auc: 0.8792 - val_f1: 0.7888 - val_loss: 0.4645 - val_precision: 0.7500 - val_recall: 0.8319\n",
      "Epoch 11/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9012 - auc: 0.9624 - f1: 0.8992 - loss: 0.2526 - precision: 0.8868 - recall: 0.9145\n",
      "Epoch 11: val_accuracy did not improve from 0.80859\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9013 - auc: 0.9624 - f1: 0.8994 - loss: 0.2524 - precision: 0.8873 - recall: 0.9143 - val_accuracy: 0.7891 - val_auc: 0.8760 - val_f1: 0.8015 - val_loss: 0.5091 - val_precision: 0.7365 - val_recall: 0.8790\n",
      "Epoch 12/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9091 - auc: 0.9737 - f1: 0.9093 - loss: 0.2241 - precision: 0.9248 - recall: 0.8971\n",
      "Epoch 12: val_accuracy did not improve from 0.80859\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9094 - auc: 0.9737 - f1: 0.9096 - loss: 0.2237 - precision: 0.9248 - recall: 0.8976 - val_accuracy: 0.7930 - val_auc: 0.8872 - val_f1: 0.7905 - val_loss: 0.4559 - val_precision: 0.7463 - val_recall: 0.8403\n",
      "Epoch 13/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9229 - auc: 0.9763 - f1: 0.9278 - loss: 0.1962 - precision: 0.9251 - recall: 0.9310\n",
      "Epoch 13: val_accuracy improved from 0.80859 to 0.82422, saving model to best_video_model.keras\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.9228 - auc: 0.9762 - f1: 0.9275 - loss: 0.1964 - precision: 0.9245 - recall: 0.9312 - val_accuracy: 0.8242 - val_auc: 0.8813 - val_f1: 0.8035 - val_loss: 0.4815 - val_precision: 0.8519 - val_recall: 0.7603\n",
      "Epoch 14/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9633 - auc: 0.9926 - f1: 0.9645 - loss: 0.1367 - precision: 0.9666 - recall: 0.9625\n",
      "Epoch 14: val_accuracy did not improve from 0.82422\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9631 - auc: 0.9925 - f1: 0.9642 - loss: 0.1368 - precision: 0.9661 - recall: 0.9625 - val_accuracy: 0.8047 - val_auc: 0.8774 - val_f1: 0.8000 - val_loss: 0.4958 - val_precision: 0.7812 - val_recall: 0.8197\n",
      "Epoch 15/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9289 - auc: 0.9772 - f1: 0.9304 - loss: 0.1987 - precision: 0.9296 - recall: 0.9327\n",
      "Epoch 15: val_accuracy did not improve from 0.82422\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9293 - auc: 0.9774 - f1: 0.9308 - loss: 0.1978 - precision: 0.9299 - recall: 0.9331 - val_accuracy: 0.8125 - val_auc: 0.8777 - val_f1: 0.7966 - val_loss: 0.5132 - val_precision: 0.8319 - val_recall: 0.7642\n",
      "Epoch 16/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9714 - auc: 0.9962 - f1: 0.9720 - loss: 0.1111 - precision: 0.9776 - recall: 0.9666\n",
      "Epoch 16: val_accuracy did not improve from 0.82422\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9714 - auc: 0.9962 - f1: 0.9720 - loss: 0.1112 - precision: 0.9774 - recall: 0.9666 - val_accuracy: 0.8125 - val_auc: 0.8787 - val_f1: 0.8065 - val_loss: 0.5120 - val_precision: 0.7874 - val_recall: 0.8264\n",
      "Epoch 17/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9642 - auc: 0.9948 - f1: 0.9635 - loss: 0.1066 - precision: 0.9669 - recall: 0.9603\n",
      "Epoch 17: val_accuracy did not improve from 0.82422\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9641 - auc: 0.9948 - f1: 0.9633 - loss: 0.1070 - precision: 0.9668 - recall: 0.9601 - val_accuracy: 0.8242 - val_auc: 0.8807 - val_f1: 0.8178 - val_loss: 0.5094 - val_precision: 0.8080 - val_recall: 0.8279\n",
      "Epoch 18/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9399 - auc: 0.9906 - f1: 0.9406 - loss: 0.1464 - precision: 0.9588 - recall: 0.9244\n",
      "Epoch 18: val_accuracy did not improve from 0.82422\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9405 - auc: 0.9907 - f1: 0.9412 - loss: 0.1453 - precision: 0.9589 - recall: 0.9254 - val_accuracy: 0.8125 - val_auc: 0.8850 - val_f1: 0.8095 - val_loss: 0.5166 - val_precision: 0.7786 - val_recall: 0.8430\n",
      "Epoch 19/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9593 - auc: 0.9975 - f1: 0.9579 - loss: 0.0937 - precision: 0.9369 - recall: 0.9806\n",
      "Epoch 19: val_accuracy did not improve from 0.82422\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9594 - auc: 0.9975 - f1: 0.9581 - loss: 0.0937 - precision: 0.9376 - recall: 0.9803 - val_accuracy: 0.8164 - val_auc: 0.8849 - val_f1: 0.8097 - val_loss: 0.5123 - val_precision: 0.7752 - val_recall: 0.8475\n",
      "Epoch 20/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9870 - auc: 0.9983 - f1: 0.9873 - loss: 0.0662 - precision: 0.9810 - recall: 0.9938\n",
      "Epoch 20: val_accuracy improved from 0.82422 to 0.83594, saving model to best_video_model.keras\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.9868 - auc: 0.9983 - f1: 0.9871 - loss: 0.0664 - precision: 0.9807 - recall: 0.9935 - val_accuracy: 0.8359 - val_auc: 0.8917 - val_f1: 0.8346 - val_loss: 0.5098 - val_precision: 0.8030 - val_recall: 0.8689\n",
      "Epoch 21/40\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9744 - auc: 0.9983 - f1: 0.9745 - loss: 0.0754 - precision: 0.9902 - recall: 0.9596\n",
      "Epoch 21: val_accuracy did not improve from 0.83594\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9743 - auc: 0.9982 - f1: 0.9745 - loss: 0.0755 - precision: 0.9899 - recall: 0.9598 - val_accuracy: 0.8281 - val_auc: 0.8939 - val_f1: 0.8268 - val_loss: 0.5075 - val_precision: 0.7955 - val_recall: 0.8607\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_TABULAR_FEATURES = 14\n",
    "\n",
    "# Inputs\n",
    "video_input = keras.Input(shape=(MAX_FRAMES, IMG_SIZE, IMG_SIZE, 3), name='video')\n",
    "mask_input = keras.Input(shape=(MAX_FRAMES, 3, IMG_SIZE, IMG_SIZE), name='mask_flow')\n",
    "tabular_input = keras.Input(shape=(NUM_TABULAR_FEATURES,), name='tabular')\n",
    "\n",
    "# Pre trained weights\n",
    "def preprocess_resnet(x):\n",
    "    return applications.resnet50.preprocess_input(x)\n",
    "\n",
    "video_x = layers.TimeDistributed(layers.Lambda(preprocess_resnet))(video_input)\n",
    "# video_x = layers.TimeDistributed(augmentation_pipeline())(video_x)\n",
    "\n",
    "# CNN Backbone\n",
    "base_cnn = applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg',\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "base_cnn.trainable = False\n",
    "\n",
    "video_features = layers.TimeDistributed(base_cnn)(video_x)\n",
    "mask_features = layers.TimeDistributed(mask_cnn_net())(mask_input)\n",
    "\n",
    "# GRU\n",
    "video_gru_out = layers.Bidirectional(layers.GRU(128, return_sequences=False))(video_features)\n",
    "video_gru_out = layers.Dropout(0.3)(video_gru_out)\n",
    "\n",
    "mask_gru_out = layers.Bidirectional(layers.GRU(128, return_sequences=False))(mask_features)\n",
    "mask_gru_out = layers.Dropout(0.3)(mask_gru_out)\n",
    "\n",
    "# Merge video and mask\n",
    "video_final = layers.Concatenate()([video_gru_out, mask_gru_out])\n",
    "\n",
    "# Tabular part\n",
    "tabular_dense = layers.Dense(64, activation='relu')(tabular_input)\n",
    "tabular_final = layers.Dropout(0.3)(tabular_dense)\n",
    "\n",
    "# Merge all\n",
    "final_merge = layers.Concatenate()([video_final, tabular_final])\n",
    "\n",
    "final_merge = layers.BatchNormalization()(final_merge)\n",
    "final_merge = layers.Dropout(0.3)(final_merge)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(final_merge)\n",
    "\n",
    "# Final model\n",
    "model = keras.Model(\n",
    "    inputs=[video_input, mask_input, tabular_input],\n",
    "    outputs=outputs,\n",
    "    name='final_model'\n",
    ")\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-5,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.FBetaScore(beta=1.0, threshold=0.5, average='macro', name='f1'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "cbs = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_video_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(train_seq, validation_data=val_seq, epochs=40, callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEVv7ZIIdKPl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09b68e8440364a438fa1489fc1730799": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22117069aa9f4fb1977ade4b5bc44c58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "274eeaf300f04b109dd5fa84423c0051": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b42f46ccbcb4531925b22d0add8adff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbe786df26274eee8d55b0458d249683",
      "placeholder": "​",
      "style": "IPY_MODEL_274eeaf300f04b109dd5fa84423c0051",
      "value": "Resolving data files: 100%"
     }
    },
    "6b9e601d42014f358a7cb7f4a176ef13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72b8aa5eab7e4a70b1003d28e22529f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09b68e8440364a438fa1489fc1730799",
      "placeholder": "​",
      "style": "IPY_MODEL_d9c161330d8e4dc4b7fd32b4875a8886",
      "value": " 1502/1502 [00:00&lt;00:00, 26.48it/s]"
     }
    },
    "72e95d3c867249708c21428ac137f459": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8313904d2c004a37b0cb3c3bf5e82409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22117069aa9f4fb1977ade4b5bc44c58",
      "max": 1348,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4465c1d53d84e77bf2095ac06b94118",
      "value": 1348
     }
    },
    "9cafb763530b478496a7ace1c5ab8351": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba7fd9f5b1aa4072be6226a08a84355d",
      "placeholder": "​",
      "style": "IPY_MODEL_e45895be91224e159c4202e01381dcda",
      "value": " 1348/1348 [00:00&lt;00:00, 132.51it/s]"
     }
    },
    "a633de00a0784373a9b5e12ae464d356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d76363ac79b1400b8f7d99fd3eb01c04",
      "placeholder": "​",
      "style": "IPY_MODEL_6b9e601d42014f358a7cb7f4a176ef13",
      "value": "Resolving data files: 100%"
     }
    },
    "a850911a75b2470d8695975023adc0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a633de00a0784373a9b5e12ae464d356",
       "IPY_MODEL_8313904d2c004a37b0cb3c3bf5e82409",
       "IPY_MODEL_9cafb763530b478496a7ace1c5ab8351"
      ],
      "layout": "IPY_MODEL_72e95d3c867249708c21428ac137f459"
     }
    },
    "a872b854b5784842b49bce3fcbb36f7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ace7c1ffee2e40059a7104e5982c8234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4465c1d53d84e77bf2095ac06b94118": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b570bf85d6134b89a96e4d0c651883e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d344b463d7e34478bd51bcf79fed93b6",
      "max": 1502,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a872b854b5784842b49bce3fcbb36f7d",
      "value": 1502
     }
    },
    "ba7fd9f5b1aa4072be6226a08a84355d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbe786df26274eee8d55b0458d249683": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d344b463d7e34478bd51bcf79fed93b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d76363ac79b1400b8f7d99fd3eb01c04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9c161330d8e4dc4b7fd32b4875a8886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e133b5e8c7134c88b36e5d401ed93901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b42f46ccbcb4531925b22d0add8adff",
       "IPY_MODEL_b570bf85d6134b89a96e4d0c651883e7",
       "IPY_MODEL_72b8aa5eab7e4a70b1003d28e22529f2"
      ],
      "layout": "IPY_MODEL_ace7c1ffee2e40059a7104e5982c8234"
     }
    },
    "e45895be91224e159c4202e01381dcda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
